{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02425807",
   "metadata": {},
   "source": [
    "# 순환 신경망 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1cfb0",
   "metadata": {},
   "source": [
    "# Sequential Data란?\n",
    "**Sequential Data**는 데이터와 데이터가 나타난 위치가 중요한 데이터를 말한다.\n",
    "\n",
    "우리가 흔히 알고있는 대부분의 데이터들을 Squential Data라고 부르는데, 예로 Speech, Text, Image 데이터들이 Sequential Data라 할 수 있다.\n",
    "\n",
    "우리가 주식데이터를 가지고 있다고 생각해보자.\n",
    "> \n",
    "데이터 1: 2000 2050 2100 2150 (상승)\n",
    "데이터 2: 2150 2100 2050 2000 (하락) \n",
    "\n",
    "여기서 데이터 1과 2에 있는 2100이라는 숫자가 같은 의미를 가지고 있을까? \n",
    "\n",
    "상승하는 2100과 하락하는 2100은 의미가 다를 것이다. 다시말하면 2100이 \"있다/없다\"가 중요한 것이 아니라 \n",
    "2100의 위치는 어디에 있는지, 2100의 앞/뒤에는 어떤 숫자가 있는지가 중요한 것이다.\n",
    "\n",
    "하나 더 예를 들어서 이미지를 보자.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/e1ef5485-7f90-450c-860c-35a1208ef18b/image.png)\n",
    "고양이 그림이 픽셀 단위로 Suffle 되면 우리는 저 그림을 고양이라고 하지 않을 것이다. \n",
    "**Suquential Data는 어떤 데이터가 있는가 없는가도 중요하지만 어떠한 순서로 되어있는가도 매우 중요하다.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085813cb",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "RNN의 '순환'에는 어떤 의미가 있을까? 물론 '반복해서 되돌아감'을 의미한다. RNN을 살펴보자.\n",
    "![](https://images.velog.io/images/a01152a/post/b911ea8f-5c7f-4d41-9e70-51b6a6d46901/image.png)\n",
    "흔한 Fully Connected Layer이다. 입력벡터로 들어가서 layer를 지나 출력 벡터를 꺼내는 방식이다. \n",
    "\n",
    "여기에 C1,C2,Ck Layer를 추가해보자.\n",
    "![](https://images.velog.io/images/a01152a/post/7b852566-4b7b-4aa6-b0bc-44846c3329a3/image.png)\n",
    "C1, C2 ... Ck 레이어는 matmul, activation등등 processing을 진행하는 노드들과는 다르게 단지 버퍼, 메모리 어떤 값을 저장하는 용도로 쓰인다. \n",
    "\n",
    "h1, h2 ... hk 의 값을 c1, c2에 저장한다.\n",
    "\n",
    "#### 간단하게 동작 순서를 설명하면,\n",
    "- 입력 벡터 원소, 하나의 입력이 들어가면 이에 대응하여 hidden layer의 결과(h1, h2 ... hk)가 일어난다.\n",
    "\n",
    "- h는 output을 위해 다음 계층으로 전달된다.\n",
    "<span style=\"color:red\"> h을 copy하여 c1, c2 ... ck에 저장한다. (h1)</span>\n",
    "\n",
    "- 2번째 입력 벡터 원소를 입력하면, x1, x2 ... xm만 들어가는 것이 아니라, \n",
    "<span style=\"color:blue\"> 전에 저장해 놓았던 c1, c2 ... ck 값이 hidden layer에 들어간다.</span>\n",
    "\n",
    "- h는 output을 위해 다음 계층으로 전달된다.\n",
    "<span style=\"color:red\"> h을 copy하여 c1, c2 ... ck에 저장한다. (h2)</span>\n",
    "\n",
    "**... 반복**\n",
    "\n",
    "> C의 초기값은 0으로 해도 되고, 랜덤값으로 주어도 된다. \n",
    "참고로 첫번째 입력 벡터 원소에 입력할 때에도 사실 C값(초깃값)이 사용된다.\n",
    "\n",
    "이를 쉽게 블럭으로 바꾸면\n",
    "![](https://images.velog.io/images/a01152a/post/2187c607-28a8-418d-a36d-c753da8e97ce/image.png)\n",
    "이렇게 표현할 수 있다. 이렇게 보니 단순 Neural Network인게 보인다.\n",
    "\n",
    "문장을 단어로 바꾸어서 생각해보았을 때, \n",
    "train 데이터는 (x0, h0), (x1, h1), (x2, h2) ... (xt, ht) 이를 시계열 데이터로 사용할 수 있다. \n",
    "![](https://images.velog.io/images/a01152a/post/7a66efb3-4cbe-4543-bb3b-3862373fe632/image.png)\n",
    "\n",
    "RNN 계층의 순환 구조를 펼침으로써 오른쪽으로 긴 신경망으로 변신 시킬 수 있다. \n",
    "그림에서 등장하는 RNN들 모두가 실제로는 '같은 계층'인 것이 지금까지 신경망과는 다르다.\n",
    "\n",
    "RNN의 수식은 다음과 같다.\n",
    "![](https://images.velog.io/images/a01152a/post/f72e41f0-36a5-4856-b1f5-bf21270380a0/image.png)\n",
    "\n",
    "- h는 hidden state vector이라고 표현한다. (은닉 상태 벡터)\n",
    "- 행렬곱을 계산하면 그 합을 tanh함수를 이용해 변환한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea84f84",
   "metadata": {},
   "source": [
    "## BPTT\n",
    "\n",
    "**BPTT**는 '시간 방향으로 펼친 신경망의 오차역전파법' (Backpropagation Through Time)을 의미한다.\n",
    "![](https://images.velog.io/images/a01152a/post/31e2c5cb-b1c4-4d8a-891a-6d9ade2c28b7/image.png)\n",
    "이전 모델과 같이 순전파를 수행하고, 이어서 역전파를 수행하여 원하는 기울기를 구할 수 있다. \n",
    "여기서 사용하는 오차역전파 법이 BPTT이다. 하지만 긴 시계열 데이터 학습할 때 문제가 생긴다. \n",
    "\n",
    "바로 **역전파 과정에서 상당한 컴퓨팅 메모리를 사용한다는 것과, 너무 Sensitive한 gradient를 얻는 다는 것이다.**\n",
    "\n",
    "## BPTT 문제점\n",
    "\n",
    "RNN은 Long Term Dependency를 잘 모델링 하지 못한다.\n",
    "![](https://images.velog.io/images/a01152a/post/1433997b-66ea-4d78-80a1-8cc430607c15/%EB%85%B8%ED%8A%B8_20210728_010947_03.jpg)\n",
    "\n",
    "만약에 O5를 구하려고 W의 값을 조정하면 너무 sensitive해서 exponential decay로 W이 0이 되어 소멸하거나, \n",
    "exponential growth로 기하급수적으로 증가할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae3ee3",
   "metadata": {},
   "source": [
    "## Truncated BPTT\n",
    "\n",
    "그래서 해결 방법이 신경망 연결을 적당한 길이로 '끊는 것'인데, '역전파'의 연결만 끊어 블록단위로 학습을 하는 것이 포인트이다.\n",
    "\n",
    "만약 1,000개의 시계열 데이터가 있다고 한다면, RNN 계층이 1,000개나 늘어선 신경망이 된다. \n",
    "![](https://images.velog.io/images/a01152a/post/e804df21-4df4-4bb2-baf2-dc89ceb3c3a4/image.png)\n",
    "기존 BPTT로 하면 당연히 방금 언급한 것과 같은 문제가 생긴다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/3376f7ef-235f-4bb5-88f9-294871370916/image.png)\n",
    "\n",
    "그래서 역전파의 연결을 단위로 끊어서 학습하게된다. 이러면 단위보다 미래의 데이터에 대해서는 생각할 필요가 없어진다. \n",
    "\n",
    "즉 **블록**으로 만들어, 독립적으로 오차역전파법을 시킨다.\n",
    ">\n",
    "중요한점은 **순전파 연결은 끊지 않는다는 것**이다. 이는 데이터를 순서대로 입력한다는 것을 말한다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/871a0450-9eed-46ce-ab92-5b8dc4b80c62/image.png)\n",
    "\n",
    "가중치 갱신은 첫 번째 블록이 블록 내부에서 순전파를 실행하고 \n",
    "\n",
    "역전파 과정을 거쳐서 기울기를 바탕으로 갱신 된 가중치 조건들이\n",
    "\n",
    "두 번째 블록의 가중치 초기 조건으로 사용된다.\n",
    "\n",
    "마찬가지로 두 번째 블록의 계층들이 해당 초기 가중치 조건으로 순전파를 진행한 후\n",
    "\n",
    "다시 끝에서 처음까지(블록 안 기준) 역전파를 해서 갱신된 가중치 조건들이 \n",
    "\n",
    "세 번째 블록의 가중치 초기 조건으로 사용된다.\n",
    "\n",
    "이런식으로 반복이되고 이를 통해 <span style=\"color:red\">**기존 블록의 갱신된 가중치가 다음 블록으로 넘어가서 실행되고 갱신되므로 역전파를 끊어서 사용해도 학습에 크게 지장이 없다**</span>는 것을 알 수 있다.\n",
    "\n",
    "## 미니배치 학습\n",
    "\n",
    "지금까지의 설명은 미니배치 수가 1일 때를 설명했다.\n",
    "미니배치 학습이 좋은 측면이 있어서, 미니 배치를 하기위해 데이터를 주는 시작 위치를 각 미니 배치의 시작 위치로 '옮겨줘야'한다. \n",
    "\n",
    "> \n",
    "'옮긴다'라는 뜻을 길이가 1000인 시계열 데이터에 대해서 시각의 길이를 10개 단위로 잘라 Truncated BPTT로 학습하는 경우를 예로한다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/d7123724-1ee0-4bb7-b401-ff4a36993f9a/image.png)\n",
    "\n",
    "미니배치 수를 2개로 구성한다고 하면,\n",
    "\n",
    "첫 번째 미니 배치 때는 0번부터 순서대로 499번 까지 10개씩 묶을 것이다.(50 묶음)\n",
    "\n",
    "두 번째 미니 배치 때는 500번째 데이터를 시작으로 999번까지 10개씩 묶어 (50 묶음) 배치의 수가 2개인 데이터를 만든다.\n",
    "\n",
    "그리고 미니 배치별로 데이터를 제공하는 시작위치를 옮겨준다.\n",
    "\n",
    "이처럼 미니배치 학습을 수행할 때는 \n",
    "1. **각 미니배치의 시작 위치를 오프셋으로 옮겨**준 후 **순서대로** 제공하면 된다.\n",
    "2. 데이터를 순서대로 입력하다 끝에 도달하면 다시 처음부터 입력하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbaa26f",
   "metadata": {},
   "source": [
    "# RNN 구현\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/44767b5d-1419-4e44-8460-b016c1d6048b/image.png)\n",
    "Time RNN 계층 : 순환 구조를 펼친 후의 계층들을 하나의 계층으로 간주한다.\n",
    "\n",
    "우리가 구현 할 신경망은 가로 방향으로 펼친 신경망이다.\n",
    "\n",
    "Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층을 'RNN 계층'이라고 하고, T개 단계분의 작업을 한꺼번에 처리하는 계층을 'Time RNN 계층'이라고 한다.\n",
    "> 시계열 데이터를 한꺼번에 처리하는 계층 앞에 'Time'을 붙이겠다. ex. Time Affine, Time Embedding\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/13e3795a-4c96-45bf-a3ad-04a123b808c4/image.png)\n",
    "\n",
    "RNN의 순전파 식이다. (이전글에서 설명 함!)\n",
    "여기에서 데이터를 미니배치로 모아서 처리한다.\n",
    "```xt```와 ```ht```에 각 샘플 데이터를 행 방향(N)에 저장한다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/d88c602b-d8cb-47b8-94c5-2c43ebfdeff0/image.png)\n",
    "- ```N``` : 미니배치 크기\n",
    "- ```D``` : 입력 벡터의 차원수\n",
    "- ```H``` : 은닉 상태 벡터의 차원수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a41ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405958df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cacahe = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dwx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = dWb\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6a189",
   "metadata": {},
   "source": [
    "**```__init__```**\n",
    " - ```params``` 변수에 2개의 가중치와 1개의 편향을 저장\n",
    " - ```grads``` 변수에 각 매개변수에 대응하는 형태로 기울기를 초기화 한 후 저장한다.\n",
    " - ```cache```는 역전파 계산 시 사용하는 중간 데이터를 담아야 하기 때문에 만든다.\n",
    "\n",
    "\n",
    " **```forward```**\n",
    " - 입력 x와 이전의 h_prev 값을 받아온다.\n",
    " - 식 그대로 순전파를 구현한다.\n",
    " - cache에 저장\n",
    " \n",
    " 역전파는 어떻게 될까?\n",
    "![](https://images.velog.io/images/a01152a/post/03033142-18fa-48c5-9871-a5284c5a8024/image.png)\n",
    "그림처럼 손실함수 J에 대한 미분은 연쇄법칙을 사용하여 RNN으로 역전파 된다.\n",
    "\n",
    "**```backward```**\n",
    "![](https://images.velog.io/images/a01152a/post/0803427e-4df4-48f0-9c19-3fa4b87b6c27/image.png)\n",
    "그림에서 나오는 식을 그대로 위의 코드로 넣었다.\n",
    "tanh를 미분하면 1-tanh**2의 값이 나오는 것을 참고해서 직접 미분해보면 쉽게 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345a1d6",
   "metadata": {},
   "source": [
    "# Time RNN 구현\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/acc526d7-92a4-4d85-b966-880feef48884/image.png)\n",
    "\n",
    "Time RNN 구조를 배웠으니, Time RNN 계층은 은닉 상태를 인스턴스 변수 h로 보관하는 것을 눈치 챌 수 있다.\n",
    "\n",
    "그러면 은닉 상태를 다음 블록에 인계할 수 있다.\n",
    "\n",
    "RNN 계층의 은닉 상태를 Time RNN 계층에서 관리한다.\n",
    "- 이렇게 하면 Time RNN 사용자는 RNN 계층 사이에서 은닉 상태를 '인계하는 작업'을 생각하지 않아도 된다는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        def __init__(self, Wx, Wh, b, stateful=False):\n",
    "            self.params = [Wx, Wh, b]\n",
    "            self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "            self.layers = None\n",
    "            \n",
    "            self.h, self.dh = None, None\n",
    "            self.stateful = stateful\n",
    "            \n",
    "        def set_state(self, h):\n",
    "            self.h = h\n",
    "        \n",
    "        def reset_state(self):\n",
    "            self.h = None\n",
    "            \n",
    "        def forward(self, xs):\n",
    "            Wx, Wh, b = self.params\n",
    "            N, T, D = xs.shape\n",
    "            D, H = Wx.shape\n",
    "            \n",
    "            self.layers = []\n",
    "            hs = np.empty((N, T, H), dtype='f')\n",
    "            \n",
    "            if not self.stateful or self.h is None:\n",
    "                self.h = zp.zeros((N, H), dtype='f')\n",
    "                \n",
    "            for t in range(T):\n",
    "                layer = RNN(*self.params)\n",
    "                self.h = layer.forward(xs[:, t, :], self.h)\n",
    "                hs[:, t, :] = self.h\n",
    "                self.layers.append(layer)\n",
    "            \n",
    "            return hs\n",
    "        \n",
    "        def backward(self, dhs):\n",
    "            Wx, Wh, b = self.params\n",
    "            N, T, H = dhs.shape\n",
    "            D, H = Wx.shape\n",
    "            \n",
    "            dxs = np.empty((N, T, D), dtype='f')\n",
    "            dh = 0\n",
    "            grads = [0, 0, 0]\n",
    "            for t in reversed(range(T)):\n",
    "                layer = self.layers[t]\n",
    "                dx, dh = layer.backward(dhs[:, t, :] + dh) # dht + dhnext 합산된 기울기\n",
    "                dxs[:, t, :] = dx\n",
    "                \n",
    "                for i, grad in enumerate(layer.grads):\n",
    "                    grads[i] += grad\n",
    "            \n",
    "            for i, grad in enumerate(grads):\n",
    "                self.grads[i][...] = grad\n",
    "            self.dh = dh\n",
    "            \n",
    "            return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1675aba4",
   "metadata": {},
   "source": [
    "**```__init__```**\n",
    "- 가중치와 편향, stateful이라는 boolean 값을 인수로 받는다. ```stateful```은 은닉 상태를 인계받을지를 조정하기 위해 있는 변수이다. (True : 유지)\n",
    "\n",
    " '유지한다'는 말은 해당 시간의 은닉 상태를 메모리에서 기억하고 있겠다는 의미이다.\n",
    "\n",
    " 긴 시계열 데이터를 처리할 때 RNN의 은닉 상태를 유지하며, Time RNN 계층의 순전파를 끊지 않고 전파한다는 의미가 내포되어 있다.\n",
    " \n",
    " Flase인 경우는 은닉 상태를 '영행렬'(모든 요소가 0인 행렬)로 초기화한다. 이것이 상태가 없는 모드이며, '무상태'라고 한다.\n",
    "\n",
    "\n",
    "- ```layers``` 인스턴스에 RNN 계층을 리스트로 저장한다.\n",
    "- ```h```는 forward()시 마지막 RNN 계층의 은닉 상태를 저장한다.\n",
    "- ```dh```는 backward()를 불렀을 때 하나 앞 블록의 은닉 상태의 기울기를 저장한다.\n",
    "\n",
    " **```forward```**\n",
    " - 매개변수 인자 ```xs```로 입력을 받는다 ```xs```는 T개 분량의 시계열 데이터를 하나로 모은 것이다.\n",
    " - ```N``` : 미니배치 크기\n",
    " - ```T``` : T개 분량 시계열 데이터를 하나로 모은 것\n",
    " - ```D``` : 입력 벡터의 차원 수\n",
    " \n",
    " - h는 처음 호출 시 (self.h가 None일 때)에는 원소가 모두 0인 영행렬로 초기화 된다. 그리고 인스턴스 변수 stateful이 False일 때도 항상 영행렬로 초기화 한다.\n",
    " \n",
    " - ```hs```: 출력값을 담을 변수이다.\n",
    " - 다음으로 for문 안에서 T번 반복하여 RNN 계층을 생성한다.\n",
    " - 계층 생성과 동시에 ```forward()```로 ```h```를 계산하고 이를 ```hs```에 해당 인덱스(시각)의 값으로 설정한다.\n",
    " ```h```에는 마지막 RNN 계층의 은닉 상태가 저장된다. \n",
    " 그래서 다음번 ```forward()``` 메서드 호출 시 ```stateful```이  True면 먼저 저장된 h값이 이용되고, \n",
    " False면 다시 영행렬로 초기화 된다.\n",
    " \n",
    "  ```layer = RNN(*self.params)```을 보면 T에 대해서 같은 params을 넣는 것을 볼 수 있는데, RNN의 의미에서 알 수 있다.\n",
    "  \n",
    "  \n",
    " > 잊지말자, RNN 계층들은 사실 하나의 계층이다.\n",
    " 시간적으로 표현하기 위해 가로로 두어 여러 계층처럼 보이지만, 본질적으로는 하나의 계층이다.\n",
    " \n",
    " 하지만 서로 다른 Time RNN 계층의 가중치 조건은 사실은 서로 다르다. (후에 설명)\n",
    " \n",
    " **```backward```**\n",
    "![](https://images.velog.io/images/a01152a/post/3cb20173-4e64-4b98-9c91-6cfd57d05056/image.png)\n",
    "\n",
    "이전과 다르게 Time RNN은 Truncated BPTT를 수행하기 때문에 이 블록의 이전 시각 역전파는 필요하지 않다.\n",
    "\n",
    "하지만 후에 seq2seq에 필요하기 때문에 이전 은닉 상태 기울기 dh는 저장해 놓는다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/ff89caa7-40f1-4bc4-9b4a-8a99b146c280/image.png)\n",
    "\n",
    "t번째 RNN 계층에서는 위로부터의 기울기 dht와 '한 시각 뒤(미래) 계층'으로부터의 기울기 dhnext가 전해진다.\n",
    "\n",
    "RNN 계층 순전파에서 출력이 2개로 분기 되어, 역전파에서는 각 기울기가 합산되어 전해진다.\n",
    "\n",
    "따라서 역전파 시 RNN 계층에는 합산된 기울기(dht + dhnext)가 입력된다.\n",
    "\n",
    "- ```dxs``` : 역전파 후 하류로 흘려보낼 기울기를 담을 변수\n",
    "- 순전파와 반대의 순서로 RNN.backward()를 호출\n",
    "- 그 시각의 기울기 dx를 dxs의 해당 인덱스에 저장한다.\n",
    "\n",
    "> 앞서 RNN 계층은 본질적으로 하나의 계층을 시간적으로 표현한 것이라고 했는데, 순전파에서는 가중치들의 조건은 같았지만 역전파에서는 시간마다 grad(기울기)들이 모두 다르다.\n",
    "그 이유는 입력받은 미분(dht) 값들이 모두 다르기 때문이다. (순전파 입장에서는 Xs값들이 각 시각마다 다르기 떄문이다.)\n",
    "\n",
    "- 가중치 매개변수에 대해서 각 RNN 계층의 가중치 기울기를 합산하여 최종 결과를 멤버 변수 ```grads```에 덮어쓴다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e255b",
   "metadata": {},
   "source": [
    "# 시계열 데이터 처리 계층 구현 RNNLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196d69d",
   "metadata": {},
   "source": [
    "RNN을 이용해서 '언어 모델'을 구현해보자.\n",
    "지금까지 시계열 데이터를 한꺼번에 처리하는 RNN계층을 구현했는데, RNNLM(RNN Language Model)을 완성해보자.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/aeda3a52-abf0-407e-890c-386b589d1609/image.png)\n",
    "\n",
    "첫 번째 Embedding 계층을 통해 ID를 단어의 분산 표현으로 변환한다.\n",
    "\n",
    "그리고 그 분산 표현이 RNN 계층으로 입력된다.\n",
    "RNN 계층은 은닉 상태를 다음 층으로 Affine 계층과 softmax계층으로 출력하며, 같은 출력을 다음 시각의 RNN 계층 쪽으로 출력한다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/53f7aebd-72d2-4812-a274-882d822a785f/image.png)\n",
    "\n",
    "softmax를 통해 나온 확률은 입력 다음에 나올 단어에 대한 확률들이 높은 것을 확인할 수 있다.\n",
    "\n",
    "> 'say'부분에서는 'goodbye', 'hello' 둘 다 높게 나왔는데 둘 다 'you say' 다음으로 자연스럽게 나올 수 있다.\n",
    "\n",
    "RNN 계층이 'you say'라는 맥락을 기억하고 있다는 것이다.\n",
    "\n",
    "즉 과거의 정보를 응집된 은닉 상태 벡터로 저장해 두고 있다.\n",
    "\n",
    "이처럼 RNNLM은 입력된 단어를 기억하고, 그것을 바탕으로 다음에 출현할 단어를 예측한다.\n",
    "\n",
    "RNN 계층이 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 저장(기억)할 수 있는 것!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bde701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') # Xavier 초기화\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful = True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70395e",
   "metadata": {},
   "source": [
    "**```__init__```**\n",
    "\n",
    "- 각 계층에서 사용하는 매개변수를 초기화한다.\n",
    "\n",
    "- Time RNN 계층의 stateful을 True로 설정한다. (은닉 상태 인계)\n",
    "\n",
    "- RNN과 Affine 초기화를 보면 **'Xavier 초깃값'**을 이용해서 노드가 n개인 경우, ```np.sqrt(n)```으로 나누어 값들을 초기화 한다.\n",
    "> 표준편차는 데이터의 차이를 직관적으로 나타내는 척도이다.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Forward와 Backward는 앞서 구축한 TimeRNN과 SoftmaxwithLoss의 코드를 사용하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2820a",
   "metadata": {},
   "source": [
    "# 퍼블렉서티\n",
    "\n",
    "언어 모델의 '평가 방법'에 대해서 알아보자.\n",
    "\n",
    "언어 모델은 주어진 과거 단어로부터 다음에 출현할 단어의 확률 분포를 출력한다.\n",
    "\n",
    "이때 언어 모델의 예측 성능을 평가하는 척도로 **퍼블렉서티(Perplexity)**를 자주 사용한다. \n",
    "\n",
    "간단하게 '확률의 역수'라고 할 수 있다.\n",
    "\n",
    "![](https://images.velog.io/images/a01152a/post/25611859-080c-42da-8944-a35e8f6bacd1/image.png)\n",
    "\n",
    "예를 들어, 'you say goodbye and I say hello .' 에서 \n",
    "\n",
    "'you' 다음으로 'say'가 나올 확률이 0.8이라고 분포되어있고 정답이 'say'라면, 이때의 확률은 0.8이다.\n",
    "\n",
    "퍼플렉서티는 이 확률의 역수 1/(0.8) = 1.25라고 할 수 있습니다.\n",
    "\n",
    "만약 say가 나올 확률이 0.2라고 나왔다면 퍼플렉서티는 5일 것입니다.\n",
    "\n",
    "퍼블렉시티는 작으수록 좋다는 것을 알 수 있다.\n",
    "\n",
    "그렇다면 퍼블렉시티 값은 무슨 의미를 가지고 있는가? **'분기수'(number of branches)**로 해석할 수 있다. \n",
    "즉, 예측한 분기수가 1.25이면 'you'라는 단어 다음 출현할 후보가 1개로 좁혀졌다는 이야기이다.\n",
    "\n",
    "분기수가 5이면, 다음 출현할 후보가 5개라는 의미이다. \n",
    "찍기전의 시험지의 5지선다 같은 느낌이다.\n",
    "\n",
    "지금은 입력데이터가 하나일 때의 이야기이고 여러 개일 때는 다음 공식을 따른다.\n",
    "![](https://images.velog.io/images/a01152a/post/1b4179b9-b409-4544-a085-1086d51d1d52/image.png)\n",
    "\n",
    "- ```N``` : 데이터의 총 개수\n",
    "\n",
    "- ```tn``` : 원핫 벡터로 나타낸 정답 레이블\n",
    "\n",
    "- ```tnk``` : n 개째 데이터의 k번째 값을 의미\n",
    "\n",
    "- ```ynk``` : 확률분포(신경망에서는 softmax의 출력)\n",
    "\n",
    "눈치챈 사람도 있겠지만, 위의 L값은 교차 엔트로피 오차식과 완전히 같다.\n",
    "\n",
    "퍼블렉서티는 L값을 이용해 exp 계산 해준 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e460016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼블렉서티 385.18\n",
      "| 에폭 2 | 퍼블렉서티 254.02\n",
      "| 에폭 3 | 퍼블렉서티 220.10\n",
      "| 에폭 4 | 퍼블렉서티 212.82\n",
      "| 에폭 5 | 퍼블렉서티 204.32\n",
      "| 에폭 6 | 퍼블렉서티 201.33\n",
      "| 에폭 7 | 퍼블렉서티 197.98\n",
      "| 에폭 8 | 퍼블렉서티 196.25\n",
      "| 에폭 9 | 퍼블렉서티 191.74\n",
      "| 에폭 10 | 퍼블렉서티 192.63\n",
      "| 에폭 11 | 퍼블렉서티 189.32\n",
      "| 에폭 12 | 퍼블렉서티 192.85\n",
      "| 에폭 13 | 퍼블렉서티 190.21\n",
      "| 에폭 14 | 퍼블렉서티 190.35\n",
      "| 에폭 15 | 퍼블렉서티 189.87\n",
      "| 에폭 16 | 퍼블렉서티 186.56\n",
      "| 에폭 17 | 퍼블렉서티 184.24\n",
      "| 에폭 18 | 퍼블렉서티 181.12\n",
      "| 에폭 19 | 퍼블렉서티 183.00\n",
      "| 에폭 20 | 퍼블렉서티 185.48\n",
      "| 에폭 21 | 퍼블렉서티 181.98\n",
      "| 에폭 22 | 퍼블렉서티 179.00\n",
      "| 에폭 23 | 퍼블렉서티 177.41\n",
      "| 에폭 24 | 퍼블렉서티 177.65\n",
      "| 에폭 25 | 퍼블렉서티 175.21\n",
      "| 에폭 26 | 퍼블렉서티 176.78\n",
      "| 에폭 27 | 퍼블렉서티 171.58\n",
      "| 에폭 28 | 퍼블렉서티 169.52\n",
      "| 에폭 29 | 퍼블렉서티 171.08\n",
      "| 에폭 30 | 퍼블렉서티 165.92\n",
      "| 에폭 31 | 퍼블렉서티 165.47\n",
      "| 에폭 32 | 퍼블렉서티 159.06\n",
      "| 에폭 33 | 퍼블렉서티 161.06\n",
      "| 에폭 34 | 퍼블렉서티 157.82\n",
      "| 에폭 35 | 퍼블렉서티 155.80\n",
      "| 에폭 36 | 퍼블렉서티 150.10\n",
      "| 에폭 37 | 퍼블렉서티 145.90\n",
      "| 에폭 38 | 퍼블렉서티 143.75\n",
      "| 에폭 39 | 퍼블렉서티 136.60\n",
      "| 에폭 40 | 퍼블렉서티 132.28\n",
      "| 에폭 41 | 퍼블렉서티 133.78\n",
      "| 에폭 42 | 퍼블렉서티 127.06\n",
      "| 에폭 43 | 퍼블렉서티 119.26\n",
      "| 에폭 44 | 퍼블렉서티 115.68\n",
      "| 에폭 45 | 퍼블렉서티 112.33\n",
      "| 에폭 46 | 퍼블렉서티 111.48\n",
      "| 에폭 47 | 퍼블렉서티 105.82\n",
      "| 에폭 48 | 퍼블렉서티 100.29\n",
      "| 에폭 49 | 퍼블렉서티 96.57\n",
      "| 에폭 50 | 퍼블렉서티 92.12\n",
      "| 에폭 51 | 퍼블렉서티 89.38\n",
      "| 에폭 52 | 퍼블렉서티 84.38\n",
      "| 에폭 53 | 퍼블렉서티 80.11\n",
      "| 에폭 54 | 퍼블렉서티 76.69\n",
      "| 에폭 55 | 퍼블렉서티 71.78\n",
      "| 에폭 56 | 퍼블렉서티 67.76\n",
      "| 에폭 57 | 퍼블렉서티 65.49\n",
      "| 에폭 58 | 퍼블렉서티 61.28\n",
      "| 에폭 59 | 퍼블렉서티 57.96\n",
      "| 에폭 60 | 퍼블렉서티 54.68\n",
      "| 에폭 61 | 퍼블렉서티 54.02\n",
      "| 에폭 62 | 퍼블렉서티 50.28\n",
      "| 에폭 63 | 퍼블렉서티 46.10\n",
      "| 에폭 64 | 퍼블렉서티 43.71\n",
      "| 에폭 65 | 퍼블렉서티 42.56\n",
      "| 에폭 66 | 퍼블렉서티 40.39\n",
      "| 에폭 67 | 퍼블렉서티 38.55\n",
      "| 에폭 68 | 퍼블렉서티 34.65\n",
      "| 에폭 69 | 퍼블렉서티 32.51\n",
      "| 에폭 70 | 퍼블렉서티 32.13\n",
      "| 에폭 71 | 퍼블렉서티 30.87\n",
      "| 에폭 72 | 퍼블렉서티 28.78\n",
      "| 에폭 73 | 퍼블렉서티 26.46\n",
      "| 에폭 74 | 퍼블렉서티 25.08\n",
      "| 에폭 75 | 퍼블렉서티 24.84\n",
      "| 에폭 76 | 퍼블렉서티 22.97\n",
      "| 에폭 77 | 퍼블렉서티 21.47\n",
      "| 에폭 78 | 퍼블렉서티 19.85\n",
      "| 에폭 79 | 퍼블렉서티 18.57\n",
      "| 에폭 80 | 퍼블렉서티 17.37\n",
      "| 에폭 81 | 퍼블렉서티 16.92\n",
      "| 에폭 82 | 퍼블렉서티 16.63\n",
      "| 에폭 83 | 퍼블렉서티 15.32\n",
      "| 에폭 84 | 퍼블렉서티 14.25\n",
      "| 에폭 85 | 퍼블렉서티 13.66\n",
      "| 에폭 86 | 퍼블렉서티 12.70\n",
      "| 에폭 87 | 퍼블렉서티 12.27\n",
      "| 에폭 88 | 퍼블렉서티 11.50\n",
      "| 에폭 89 | 퍼블렉서티 10.85\n",
      "| 에폭 90 | 퍼블렉서티 10.23\n",
      "| 에폭 91 | 퍼블렉서티 10.04\n",
      "| 에폭 92 | 퍼블렉서티 9.70\n",
      "| 에폭 93 | 퍼블렉서티 8.69\n",
      "| 에폭 94 | 퍼블렉서티 8.68\n",
      "| 에폭 95 | 퍼블렉서티 8.48\n",
      "| 에폭 96 | 퍼블렉서티 7.58\n",
      "| 에폭 97 | 퍼블렉서티 7.83\n",
      "| 에폭 98 | 퍼블렉서티 7.19\n",
      "| 에폭 99 | 퍼블렉서티 6.63\n",
      "| 에폭 100 | 퍼블렉서티 6.42\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기 (전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력\n",
    "ts = corpus[1:] # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "            \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    # 에폭마다 퍼블렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼블렉서티 %.2f' % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf651d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57fe36c",
   "metadata": {},
   "source": [
    "# RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42084dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 419.19\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 385.30\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 265.95\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 222.54\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 210.74\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 208.71\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.67\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.63\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 194.88\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 190.24\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.00\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.04\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.26\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 186.45\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 185.58\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 189.62\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 188.34\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 182.94\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 179.51\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 179.62\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 176.80\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 175.94\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 179.44\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 174.07\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 168.35\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.29\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 168.29\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 167.28\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 162.51\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 156.52\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 157.10\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 148.65\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 149.56\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 148.94\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 142.01\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 138.05\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 137.10\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 129.30\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 126.82\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 120.85\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 114.48\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 116.59\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 110.38\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 108.03\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 99.61\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 96.70\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 94.38\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 90.87\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 85.21\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 79.69\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 77.23\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 73.33\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 72.65\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 66.65\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 63.04\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 59.74\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 59.66\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 54.89\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 51.63\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 48.64\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 44.93\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 43.50\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 41.38\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 39.66\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 36.86\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 34.97\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 33.41\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 32.09\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 30.59\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 28.52\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 27.50\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 25.13\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 23.88\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 22.56\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 21.40\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 20.26\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 19.53\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 17.61\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 17.16\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 15.75\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 15.07\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.28\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.30\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.69\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 12.17\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 12.76\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 11.62\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.49\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.57\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 9.49\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 9.57\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.63\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.27\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.08\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.59\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.28\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.91\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.82\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.00\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 5.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd1bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
